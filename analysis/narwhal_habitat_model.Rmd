---
title: "Narwhal habitat model"
author: "Marie Zahn"
date: '2022-12-12'
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = 'C:/Users/marie/Documents/OMG_Narwhals/OMG_narwhals_habitat-model')
```

```{r load packages}
library(tidyverse)
library(corrplot)
library(MuMIn)
library(arm)
library(faraway)
library(ggplot2)
library(sjPlot)
library(here)
library(car)
library(ggpubr)
library(raincloudplots)
```

## Open Data

```{r open rdata files}
# reload data from anywhere
# data from Aug-Oct
load(here("data-cleaning_R/narwhal_model_data_aug-oct.rdata")) 
```

## Compare detections in 2019

```{r narwhal detection totals}
## pool soundtrap and aural detections for 2019 data (i.e., take only one obs/day for each site)
mdl_data_pooled_2019 <- mdl_data %>% group_by(site,time) %>% 
  filter(year==2019, narwhal==max(narwhal),(row_number()==n()))
## pool detections for entire dataset (i.e., pool 2019 but retain 2018 detections)
mdl_data_pooled <- mdl_data %>% group_by(site,time) %>% 
  filter(narwhal==max(narwhal),(row_number()==n())) %>% dplyr::select(-device)

## identify how many detections from the same day occurred at more than one site
length(unique(mdl_data_pooled$time)) # number of days (obs) for open water period
sum(mdl_data_pooled$narwhal) # total of 93 detections over two years at 3 sites (92 not counting outlier)
narwhal_dets <- mdl_data_pooled %>% filter(narwhal==1) # number of days that narwhals were detected
length(unique(narwhal_dets$time)) # number of unique days when narwhals were identified (76)

## determine how many days whales were seen at more than one glacier front
mult_det <- mdl_data_pooled %>% dplyr::select(time, site, narwhal) %>% pivot_wider(names_from = site, values_from = narwhal) %>% mutate(rowsums = sum(kong,rink,sver,na.rm=TRUE)) %>% filter(rowsums>1)
length(mult_det$time)

## tally up total detections for each site for a given year
rink_2018 <- mdl_data_pooled %>% filter(year==2018, site=='rink')
rink_2019 <- mdl_data_pooled %>% filter(year==2019, site=='rink')
sum(rink_2018$narwhal)
sum(rink_2019$narwhal)+1 # (add outlier that was removed)

kong_2018 <- mdl_data_pooled %>% filter(year==2018, site=='kong')
kong_2019 <- mdl_data_pooled %>% filter(year==2019, site=='kong')
sum(kong_2018$narwhal)
sum(kong_2019$narwhal)

sver_2018 <- mdl_data_pooled %>% filter(year==2018, site=='sver')
sum(sver_2018$narwhal)

```

Out of the 77 days that narwhals were detected, 16 of those days were occasions when whales were detected at two locations on the same day. Whales were never detected at three locations on the same day in 2018.

Totals between each year/site

2018
* Rink: 13
* Kong Oscar: 8
* Sverdrup: 7

2019
* Rink: 32
* Kong Oscar: 33

## Aural vs soundtrap

```{r aural vs soundtrap 2019}
## see whether there are any aural detections that were NOT detected by the soundtrap in 2019
aural_2019 <- mdl_data %>% group_by(site) %>% filter(year==2019,device=='aural') %>% dplyr::select(time,narwhal) %>% rename(narwhal_aural=narwhal)
sound_2019 <- mdl_data %>% group_by(site) %>%  filter(year==2019,device=='soundtrap') %>% dplyr::select(time,narwhal)%>% rename(narwhal_sound=narwhal)

compare <- aural_2019 %>% group_by(site) %>%  left_join(sound_2019,by="time") %>% filter(site.x==site.y, narwhal_aural==1 & narwhal_sound==0)
compare # zero rows = no aural detections that were not picked up by soundtrap

## check sums across years
sum(mdl_data_pooled$narwhal)
mdl_data %>% filter(year==2018) %>% dplyr::select(narwhal) %>% sum()
mdl_data %>% filter(year==2019,device=='soundtrap') %>% dplyr::select(narwhal) %>% sum()

## double check comparison using different method
aural_2019_kong <- aural_2019 %>% filter(site=='kong') 
sound_2019_kong <- sound_2019 %>% filter(site=='kong') 
aural_2019_rink <- aural_2019 %>% filter(site=='rink') 
sound_2019_rink <- sound_2019 %>% filter(site=='rink') 

aural_2019_kong %>% left_join(sound_2019_kong,by="time") %>% filter(narwhal_aural==1&narwhal_sound==0)
aural_2019_rink %>% left_join(sound_2019_rink,by="time") %>% filter(narwhal_aural==1&narwhal_sound==0)

```

## Normalize glacier length data

```{r normalize glacier length data}
## normalize at the start of each year
ref <- mdl_data_pooled %>% group_by(year, site) %>% filter(time==min(as.Date(time))) %>% dplyr::select(site,year,glacier_length) %>% dplyr::rename(length_ref=glacier_length)

## add normalized glacier length variable and drop unneeded variables
mdl_data_clean <- mdl_data_pooled %>% left_join(ref,by=c("site","year")) %>% mutate(glacier_len_norm = glacier_length - length_ref) %>% dplyr::select(!c(length_ref,noise_100Hz,noise_2kHz,runoff_mar,glacier_length))

## sanity check plot
mdl_data_clean %>% ggplot(aes(x=as.Date(time),y=glacier_len_norm,color=site))+
  geom_point()

## make sure data are correct
mdl_data %>% filter(time=='2019-09-01')
mdl_data_clean %>% filter(time=='2019-09-01')
  
```

```{r check correlations}
## check correlations now that glacier length has been normalized
## Aug-Oct period
mdl_data_corr <- mdl_data_clean %>% ungroup() %>% dplyr::select(!c(narwhal, time, site, year)) %>% cor(use = "complete.obs")
## plot correlation test
corrplot::corrplot(mdl_data_corr, method = 'number')

## Hide upper triangle and export csv of correlations
mdl_data_tbl <- mdl_data_clean %>% ungroup() %>% dplyr::select(!c(narwhal, time, site, year)) %>% cor(use = "complete.obs") %>% round(2) %>% as.data.frame()

mdl_data_tbl[upper.tri(mdl_data_tbl)]<-""
mdl_data_tbl<-as.data.frame(mdl_data_tbl)
write.csv(mdl_data_tbl, here("analysis/mdl_data_pooled_correlations.csv"),row.names = TRUE)
```

## Exploratory plots

```{r raincloud plots}
variables <- c("DOY","runoff_racmo","salt_shallow","salt_deep","temp_shallow","temp_deep",
               "ice_cover_percent","velocity","noise_4kHz","glacier_len_norm")

raincloud_list <- list()

for (i in 1:length(variables)){
  data_1 <- mdl_data_clean %>% filter(narwhal==1) %>% dplyr::select(variables[i])
  data_2 <- mdl_data_clean %>% filter(narwhal==0) %>% dplyr::select(variables[i])
  
  # make dataframe
  df_1x1 <- data_1x1(
    array_1 = unlist(array(data_1[variables[i]])),
    array_2 = unlist(array(data_2[variables[i]])),
    jit_distance = .09,
    jit_seed = 321)
  
  # plot
  raincloud_2 <- raincloud_1x1_repmes(
    data = df_1x1,
    colors = (c('dodgerblue', 'darkorange')),
    fills = (c('dodgerblue', 'darkorange')),
    line_color = 'white',
    line_alpha = .3,
    size = 1,
    alpha = .6,
    align_clouds = FALSE) +
   
  scale_x_continuous(breaks=c(1,2), labels=c("1", "0"), limits=c(0, 3)) +
    xlab("Narwhal") + 
    ylab(variables[i]) +
    theme_classic()
  
  raincloud_list[[i]] <- raincloud_2
}

ggarrange(raincloud_list[[1]],raincloud_list[[2]],raincloud_list[[3]],
          raincloud_list[[4]],raincloud_list[[5]],raincloud_list[[6]],
          raincloud_list[[7]],raincloud_list[[8]],raincloud_list[[9]],
          raincloud_list[[10]],ncol=3, nrow=4)

```

```{r raincloud plots - scaled vars}

# scale data and ensure vars are numeric and drop na (=select complete observations)
model_data_scale <- mdl_data_pooled %>%
  mutate_at(vars(runoff_racmo,salt_shallow,temp_shallow,salt_deep,temp_deep,ice_cover_percent,
                 velocity,glacier_len_norm,DOY),as.numeric) %>%
  mutate_at(vars(runoff_racmo,salt_shallow,temp_shallow,salt_deep,temp_deep,ice_cover_percent,
                 velocity,glacier_len_norm,DOY),scale)

model_data_scale <- as.data.frame(mdl_data_pooled) %>%
  mutate_at(vars(runoff_racmo,salt_shallow,temp_shallow,salt_deep,temp_deep,ice_cover_percent,
                 velocity,glacier_len_norm,DOY),scale)

variables <- c("DOY","runoff_racmo","salt_shallow","salt_deep","temp_shallow","temp_deep",
               "ice_cover_percent","velocity","noise_4kHz","glacier_len_norm")

raincloud_list <- list()

for (i in 1:length(variables)){
  data_1 <- model_data_scale %>% filter(narwhal==1) %>% dplyr::select(variables[i])
  data_2 <- model_data_scale %>% filter(narwhal==0) %>% dplyr::select(variables[i])
  
  # make dataframe
  df_1x1 <- data_1x1(
    array_1 = unlist(array(data_1[variables[i]])),
    array_2 = unlist(array(data_2[variables[i]])),
    jit_distance = .09,
    jit_seed = 321)
  
  # plot
  raincloud_2 <- raincloud_1x1_repmes(
    data = df_1x1,
    colors = (c('dodgerblue', 'darkorange')),
    fills = (c('dodgerblue', 'darkorange')),
    line_color = 'white',
    line_alpha = .3,
    size = 1,
    alpha = .6,
    align_clouds = FALSE) +
   
  scale_x_continuous(breaks=c(1,2), labels=c("1", "0"), limits=c(0, 3)) +
    xlab("Narwhal") + 
    ylab(variables[i]) +
    theme_classic()
  
  raincloud_list[[i]] <- raincloud_2
}

```

## Run models

```{r global glm}
## logistic regression - glm with binomial response and logit link 
## make sure year is coded as a factor
mdl_data_clean <- mdl_data_clean %>% mutate_at(vars(year), list(factor))

# removed velocity because the distribution is broken between sites (See plots above)
# DOY is correlated with salt_deep (dropping salt_deep)
# temp_deep and salt_shallow are correlated (dropping salt_shallow)

## run global model with sea ice
mdl_gbl_ice <- glm(narwhal ~ 
                 ice_cover_percent+
                 runoff_racmo+
                 glacier_len_norm+
                 noise_4kHz+
                 year+
                 site+
                 temp_shallow+
                 temp_deep+
                 DOY+
                 DOY:temp_shallow+
                 DOY:temp_deep+
                 ice_cover_percent:DOY+
                 ice_cover_percent:temp_shallow+
                 ice_cover_percent:temp_deep,
               data = mdl_data_clean,
               family=binomial(link="logit"),
               na.action="na.fail")

# check vif for collinearity
round(car::vif(mdl_gbl_ice),3)

# partial residual plots
crPlots(mdl_gbl_ice)

# print summary output
summary(mdl_gbl_ice)
faraway::sumary(mdl_gbl_ice)

# run all possible model combinations
dredge_mdl_gbl_ice <- dredge(mdl_gbl_ice)
head(dredge_mdl_gbl_ice)

# export table to csv
write.csv(as.data.frame(dredge_mdl_gbl_ice), row.names = FALSE,
          here("analysis/csv_outputs/mdl_results.csv"))


## run global model without sea ice
mdl_gbl <- glm(narwhal ~ 
                 # runoff_racmo+
                 glacier_len_norm+
                 noise_4kHz+
                 year+
                 site+
                 temp_shallow+
                 temp_deep+
                 DOY+
                 DOY:temp_shallow+
                 DOY:temp_deep,
               data = mdl_data_clean,
               family=binomial(link="logit"),
               na.action="na.fail")

# print summary output
summary(mdl_gbl)
faraway::sumary(mdl_gbl)

# run all possible model combinations
dredge_mdl <- dredge(mdl_gbl)
head(dredge_mdl)

```


```{r global glm - scaled data}
## logistic regression - glm with binomial response and logit link 
## make sure year is coded as a factor
mdl_data_clean <- mdl_data_clean %>% mutate_at(vars(year), list(factor))

## scale data
model_data_scale <- as.data.frame(mdl_data_clean) %>%
  mutate_at(vars(runoff_racmo,salt_shallow,temp_shallow,salt_deep,temp_deep,ice_cover_percent,
                 velocity,glacier_len_norm,DOY),scale)

# removed velocity because the distribution is broken between sites (See plots above)
# DOY is correlated with salt_deep (dropping salt_deep)
# temp_deep and salt_shallow are correlated (dropping salt_shallow)

## run global model with sea ice
mdl_gbl_ice <- glm(narwhal ~ 
                 ice_cover_percent+
                 runoff_racmo+
                 glacier_len_norm+
                 noise_4kHz+
                 year+
                 site+
                 temp_shallow+
                 temp_deep+
                 DOY+
                 DOY:temp_shallow+
                 DOY:temp_deep+
                 ice_cover_percent:DOY+
                 ice_cover_percent:temp_shallow+
                 ice_cover_percent:temp_deep,
               data = model_data_scale,
               family=binomial(link="logit"),
               na.action="na.fail")

# check vif for collinearity
round(car::vif(mdl_gbl_ice),3)

# partial residual plots
crPlots(mdl_gbl_ice)

# print summary output
summary(mdl_gbl_ice)
faraway::sumary(mdl_gbl_ice)

# run all possible model combinations
dredge_mdl_gbl_ice <- dredge(mdl_gbl_ice)
head(dredge_mdl_gbl_ice)

# export table to csv
write.csv(as.data.frame(dredge_mdl_gbl_ice), row.names = FALSE,
          here("analysis/csv_outputs/mdl_results.csv"))


## run global model without sea ice
mdl_gbl <- glm(narwhal ~ 
                 # runoff_racmo+
                 glacier_len_norm+
                 noise_4kHz+
                 year+
                 site+
                 temp_shallow+
                 temp_deep+
                 DOY+
                 DOY:temp_shallow+
                 DOY:temp_deep,
               data = model_data_scale,
               family=binomial(link="logit"),
               na.action="na.fail")

# print summary output
summary(mdl_gbl)
faraway::sumary(mdl_gbl)

# run all possible model combinations
dredge_mdl <- dredge(mdl_gbl)
head(dredge_mdl)

```


```{r best models}
## global model includes sea ice and runoff
mdl_best <- glm(narwhal ~
                  DOY+
                  glacier_len_norm+
                  ice_cover_percent+
                  temp_deep+
                  temp_shallow+
                  DOY:temp_deep+
                  site,
                data = mdl_data_clean,
                family=binomial(link="logit"),
                na.action="na.fail")

round(car::vif(mdl_best),2)
# print summary output
summary(mdl_best)
faraway::sumary(mdl_best)
## 95% CI for beta_i based on profile likelihood
round(confint(mdl_best), 3)

## global model includes runoff but not sea ice
mdl_best <- glm(narwhal ~
                  runoff_racmo+
                  DOY+
                  year,
                data = mdl_data_clean,
                family=binomial(link="logit"),
                na.action="na.fail")

round(car::vif(mdl_best),2)
# print summary output
summary(mdl_best)
faraway::sumary(mdl_best)
## 95% CI for beta_i based on profile likelihood
round(confint(mdl_best), 3)

## best model for no sea ice and no runoff
mdl_best <- glm(narwhal ~
                  DOY+
                  noise_4kHz+
                  temp_deep+
                  DOY:temp_deep+
                  year,
                data = mdl_data_clean,
                family=binomial(link="logit"),
                na.action="na.fail")

round(car::vif(mdl_best),2)

# print summary output
summary(mdl_best)
faraway::sumary(mdl_best)

## 95% CI for beta_i based on profile likelihood
round(confint(mdl_best), 3)

# plot predictions
# plot_model(mdl_best_b4freeze)
# plot_model(mdl_best_b4freeze, type = 'pred',
#            transform = "exp", show.data=TRUE)

# reference this website: http://www.amelia.mn/sds291/labs/lab_logistic_regression.html
```

```{r plot logistic regression result with observations}
## sea ice cover ---------------------------------------
## plot narwhal prob vs sea ice with confidence intervals
clr <- viridis::plasma(1, 0.8, 0.5, 0.5)
## get fitted values
newdata18 <- data.frame(ice_cover_percent = seq(0, 75),
                      DOY = rep(mean(mdl_data_pooled$DOY),length(seq(0, 75))),
                      year = as.factor(rep(2018,length(seq(0, 75)))))
newdata19 <- data.frame(ice_cover_percent = seq(0, 75),
                      DOY = rep(mean(mdl_data_pooled$DOY),length(seq(0, 75))),
                      year = as.factor(rep(2019,length(seq(0, 75)))))

eta18 <- predict(mdl_best_b4freeze, newdata18)
eta19 <- predict(mdl_best_b4freeze, newdata19)
# transform out of logit space
p_hat18 <- 1 / (1 + exp(-eta18))
p_hat19 <- 1 / (1 + exp(-eta19))

## get the SE of the response
se18 <- predict(mdl_best_b4freeze, newdata18, type = "link", se.fit = TRUE)$se.fit
CI_upper18 <- 1 / (1 + exp(-(eta18 + 1.96*se18))) ## upper 95% CI
CI_lower18 <- 1 / (1 + exp(-(eta18 - 1.96*se18))) ## lower 95% CI

se19 <- predict(mdl_best_b4freeze, newdata19, type = "link", se.fit = TRUE)$se.fit
CI_upper19 <- 1 / (1 + exp(-(eta19 + 1.96*se19))) ## upper 95% CI
CI_lower19 <- 1 / (1 + exp(-(eta19 - 1.96*se19))) ## lower 95% CI

## 95% CI for beta_i based on profile likelihood
round(confint(mdl_best_b4freeze), 2)

## set plot area
par(mai = c(0.9, 0.9, 0.1, 0.1),
    omi = c(0, 0, 0, 0),
    cex.lab = 1)

## plot narwhal detections vs. ice cover
plot(narwhal ~ ice_cover_percent, data = mdl_data_pooled,
     pch = 16, cex = 1.3, col = clr,
     yaxt = "n", ylab = "Narwhal prob (%)", xlab = "Sea ice cover (%)")
axis(2, at = c(0,0.5,1), labels = c("0","50", "100"), las = 1)

# ## add 95% CI's
# lines(DOY, CI_upper, lwd = 1, col = "gray")
# lines(DOY, CI_lower, lwd = 1, col = "gray")
ice_cover_percent <- seq(0, 75)
polygon(c(ice_cover_percent, rev(ice_cover_percent)), c(CI_upper19, rev(CI_lower19)), border=NA,
        col = adjustcolor("orange",alpha.f=0.2))
polygon(c(ice_cover_percent, rev(ice_cover_percent)), c(CI_upper18, rev(CI_lower18)), border=NA,
        col = adjustcolor("gray",alpha.f=0.5))
## add model fit
lines(ice_cover_percent, p_hat18, lwd = 2, col="darkgray")
lines(ice_cover_percent, p_hat19, lwd = 2, col="orange")

## DOY ---------------------------------------
## plot narwhal prob vs DOY with confidence intervals
DOY <- seq(210,356)
## get fitted values
newdata18 <- data.frame(DOY = DOY,
                      ice_cover_percent = rep(mean(mdl_data_pooled$ice_cover_percent),length(DOY)),
                      year = as.factor(rep(2018,length(DOY))))
newdata19 <- data.frame(DOY = DOY,
                      ice_cover_percent = rep(mean(mdl_data_pooled$ice_cover_percent),length(DOY)),
                      year = as.factor(rep(2019,length(DOY))))

eta18 <- predict(mdl_best_b4freeze, newdata18)
eta19 <- predict(mdl_best_b4freeze, newdata19)
# transform out of logit space
p_hat18 <- 1 / (1 + exp(-eta18))
p_hat19 <- 1 / (1 + exp(-eta19))

## get the SE of the response
se18 <- predict(mdl_best_b4freeze, newdata18, type = "link", se.fit = TRUE)$se.fit
CI_upper18 <- 1 / (1 + exp(-(eta18 + 1.96*se18))) ## upper 95% CI
CI_lower18 <- 1 / (1 + exp(-(eta18 - 1.96*se18))) ## lower 95% CI

se19 <- predict(mdl_best_b4freeze, newdata19, type = "link", se.fit = TRUE)$se.fit
CI_upper19 <- 1 / (1 + exp(-(eta19 + 1.96*se19))) ## upper 95% CI
CI_lower19 <- 1 / (1 + exp(-(eta19 - 1.96*se19))) ## lower 95% CI

## 95% CI for beta_i based on profile likelihood
round(confint(mdl_best_b4freeze), 2)

## set plot area
par(mai = c(0.9, 0.9, 0.1, 0.1),
    omi = c(0, 0, 0, 0),
    cex.lab = 1)

## plot narwhal detections vs. ice cover
plot(narwhal ~ DOY, data = mdl_data_pooled,
     pch = 16, cex = 1.3, col = clr,
     yaxt = "n", ylab = "Narwhal prob (%)", xlab = "DOY")
axis(2, at = c(0,0.5,1), labels = c("0","50", "100"), las = 1)

# ## add 95% CI's
# lines(DOY, CI_upper, lwd = 1, col = "gray")
# lines(DOY, CI_lower, lwd = 1, col = "gray")
polygon(c(DOY, rev(DOY)), c(CI_upper19, rev(CI_lower19)), border=NA,
        col = adjustcolor("orange",alpha.f=0.2))
polygon(c(DOY, rev(DOY)), c(CI_upper18, rev(CI_lower18)), border=NA,
        col = adjustcolor("gray",alpha.f=0.5))
## add model fit
lines(DOY, p_hat18, lwd = 2, col="darkgray")
lines(DOY, p_hat19, lwd = 2, col="orange")

```

## Diagnostics

```{r diagnostics}
## plot deviance residuals------------------------------------------
## set plot area
par(mai = c(0.9, 0.9, 0.1, 0.1),
omi = c(0, 0, 0, 0),
cex.lab = 1)
## plot resids vs eta
binnedplot(fitted(mdl_global), 
           residuals(mdl_global), las = 1, pch = 16,
           ylab = "Residuals", xlab = "Fitted values",main = "")

binnedplot(fitted(mdl_global_whales), 
           residuals(mdl_global_whales), las = 1, pch = 16,
           ylab = "Residuals", xlab = "Fitted values",main = "")

## compute R^2
# deviances
# for open water period
nn <- length(mdl_data_b4freeze_pooled$time)
DM_mod <- mdl_global$deviance
D0_mod <- mdl_global$null.deviance
# R^2
(R2 <- (1 - exp((DM_mod - D0_mod) / nn)) / (1 - exp(-D0_mod / nn)))

# for period when whales were in the area
nn <- length(mdl_data_pooled_whales$time)
DM_mod <- mdl_global_whales$deviance
D0_mod <- mdl_global_whales$null.deviance
(R2 <- (1 - exp((DM_mod - D0_mod) / nn)) / (1 - exp(-D0_mod / nn)))

## leverages--------------------------------------------------------
## set plot area
par(mai = c(0.9, 1, 0.1, 0.1),
omi = c(0, 0, 0, 0),
cex.lab = 1)
levs <- hatvalues(mdl_global_whales)
## threshhold value
h_crit <- 2 * length(coef(mdl_global_whales)) / nn

## halfnormal plot
faraway::halfnorm(levs, las = 1, ylab = "")
text(0, 0.92*par("usr")[4], substitute(italic(h[crit]) == h_crit, 
                                       list(h_crit = h_crit)), pos = 4)
mtext(side = 2, text = "Sorted Data", line = 4)

## Cook's D---------------------------------------------------------
## set plot area
par(mai = c(0.9, 0.9, 0.1, 0.1),
omi = c(0, 0, 0, 0),
cex.lab = 1)
## halfnormal plot
CD <- cooks.distance(mdl_global_whales)
faraway::halfnorm(CD, las = 1, ylab = "")
mtext(side = 2, text = "Sorted Data", line = 3.5)

## H-L test with 8 groups
# A non-significant p value indicates that there is no evidence that the observed and expected frequencies differ (i.e., evidence of good fit).
library(generalhoslem)
generalhoslem::logitgof(obs = mdl_data_b4freeze_pooled$narwhal,
                        exp = fitted(mdl_global), g = 8)

generalhoslem::logitgof(obs = mdl_data_pooled_whales$narwhal,
                        exp = fitted(mdl_global_whales), g = 8)
```

```{r check autocorrelation, eval=FALSE}
acf(resid(mdl_global_b4freeze))
acf(resid(mdl_global_whales))
```

